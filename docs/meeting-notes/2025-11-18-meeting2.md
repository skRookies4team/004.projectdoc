# 프로젝트 회의록

## 회의 정보
- **회의명**: 프로젝트 회의
- **일시**: 2025.11.18
- **장소**: 강의실 372
- **회의 유형**: 기획회의

## 참석자
- **진행자**: 팀장 최대현
- **참석자**: 
  - 강소현
  - 국영규
  - 김세희
  - 모인지
  - 윤종윤
  - 이유진
  - 임성현
  - 곽진욱
  - 이상호
- **불참자**:

## 회의 안건
1. 질문 그룹핑 및 FAQ 역할 재논의
2. 외부 API 사용 시 보안·마스킹 전략
3. 내부 LLM 사용 필요성 논의
4. 인프라 및 접근·테스트 관련 논의
5. 질문 분석 기반 경영진 리포팅 기능
6. WBS 일정 관리

## 회의 내용

### 안건 1: 질문 그룹핑 및 FAQ 역할 재논의
- **논의 내용**:
  - 연차 등 특정 주제에 대한 질문을 모아 ‘보편적 질문 세트’를 만드는 방식 논의
  - CTO: 여러 질문을 그룹으로 묶는 과정 자체가 핵심 고민이며, FAQ도 차별화 요소가 될 수 있으므로 삭제하지 않는 것이 낫다고 의견 제시
  - 사용자가 선택한 응답 패턴을 기반으로 정확도를 점진적으로 높여갈 수 있음

  - 멘토: “사용자가 응답을 반드시 누르지 않을 경우 정확도 향상 전략이 작동하지 않을 수 있다”는 우려

  - FAQ 삭제 시 → 질문 트렌드 분석·경영진 보고 기능도 함께 사라질 위험

### 안건 2: 질문 분석 기반 경영진 리포팅 기능
- **논의 내용**: 
  - CTO: 질문자 유형·질문 패턴을 분석해 경영진에게 보고하는 기능이 FAQ와 일맥상통한다고 언급
  - FAQ 기능을 제거하면 해당 리포팅 기능도 함께 없어질 수 있다는 우려 제기
  - FAQ가 단순 Q&A가 아니라 “조직 내 리스크 탐지 기능” 역할도 수행할 수 있음
  - 이 기능 유지 여부가 프로젝트 차별화 포인트가 됨

### 안건 3: 외부 API 사용 시 보안·마스킹 전략
- **논의 내용**:
  - 외부 API 사용 시 보안 이슈 발생 가능 → 민감정보 마스킹이 필수
  - 외부 API로 유출되는 정보가 거의 없도록 사내 보안망과 연동된 구조 필요
  - 이는 서비스 차별화 요소가 될 수 있음(“보안 중심 Assistant”)
  - 민감정보 식별 및 마스킹 로직 복잡 → 내부 LLM 또는 사내망 우선 전략 필요

### 안건 4: 내부 LLM 사용 필요성 논의
- **논의 내용**:
  - 강사: “파인튜닝은 클라우드가 더 쉬운데 왜 온프레미스 LLM을 쓰냐?” 질문

  - 팀: 외부 LLM 사용 시 내부 문서 포함된 정보가 유출될 위험 → 내부 LLM 우선 사용 필요
  - 내부 LLM에 마스킹 로직을 구현해 민감정보 보호
  - VM 자원(10GB GPU)을 사용하는 고성능 LLM을 내부 배치하여 외부 모델 호출을 최소화할 계획
  - 2조가 VM 자원을 사용하지 않을 경우, 4조·1조가 서버를 공유해 사용할 수 있는 가능성 제기
  
  - CTO: “보안 이슈 외에는 내부 LLM을 사용할 이유가 없다” 지적

  - 멘토: 외부 LLM 실제 사용 시 토큰 비용 산정 필요 → 추후 비용 모델링 필수

  - 강사: 올라마 기반 모델 실험 필요
  - CTO: 외부 LLM이 응답 자연스러움 측면에서 유리

### 안건 5: 인프라 및 접근·테스트 관련 논의
- **논의 내용**:
  - CTO: 내부 서버·VM 테스트를 실제 물리적으로 수행해볼 것(Access 계정 등)

  - XHU 환경에서 일부 사전 작업이 되어 있음
  - 2조가 장비를 사용하지 않을 경우, 4조·1조와 장비 공유 가능성 언급

  - 자원 사용 배분 관련 협의 필요
  - 온프레미스 LLM 운영 시 GPU 자원 관리 중요

### 안건 6: WBS 일정 관리
- **논의 내용**:
  - CTO: 이번 주까지 WBS 완성 요청
  - 질문 리스트, LLM 전략, 마스킹 정책 등이 WBS 구성에 직접 영향

- **결정 사항**: 
  - FAQ 기능 유지 (삭제 불가)
    - 이유: 질문 그룹핑, 경영진 리포팅, 보안 리스크 탐지 기능에 모두 연관
            CTO·멘토 의견: FAQ는 차별화 요소로 활용해야 함
    - 일정: 기능명세서에 즉시 반영 (2025-11-18)
  - 질문 리스트 정제 및 그룹핑 작업 진행
    - 연차 등 주제별 질문을 그룹화
    - 사용자가 누른 응답 패턴 기반 정확도 향상 전략 유지
    - 일정: 이번 주 내 1차 정제 완료 (2025-11-19)
  - 내부 LLM 우선 전략 유지
    - 내부 문서·보안 정보 보호 목적
    - 민감정보 마스킹 로직을 내부 LLM에 구현
    - 외부 LLM은 자연스러운 문장 생성이 필요한 경우에 한해 제한적으로 사용
    - 일정: LLM 테스트 환경 구축 후, 다음 스프린트에 성능 확인 (2025-11-18)
  - 외부 API 사용 정책 수립
    - 외부 API 호출 시 반드시 마스킹 선처리
    - 민감정보 포함 문장은 내부 LLM에서만 처리
    - 토큰·비용 산정은 추후 상세 분석
    - 일정: 보안정책서 및 챗봇 시나리오에 반영 (2025-11-18)
  - VM·온프레미스 환경 테스트
    - XHU·Access 계정 기반 실제 접속 및 모델 테스트 수행
    - 2조 장비 미사용 시 4조·1조·2조 간 서버 공유 논의
    - 일정: 다음 회의 전에 초기 테스트 수행 (2025-11-19)
  - WBS 이번 주 내 완성
    - LLM 전략·보안 정책·질문 리스트 작업 반영
    - 일정: 주말까지 초안 완성 (2025-11-19)

## 다음 회의
- **일시**: 2025-11-19

## 기타 사항
- 모든 회의록은 GitHub의 docs/meeting-notes/ 디렉토리에 저장
- 회의록은 회의 종료 후 24시간 내에 공유

---
**작성자**: 이유진  
**작성일**: 2025-11-18