# 프로젝트 회의록

## 회의 정보
- **회의명**: 프로젝트 회의
- **일시**: 2025.11.29
- **장소**: 강의실 394
- **회의 유형**: 기획회의

## 참석자
- **진행자**: 팀장 최대현
- **참석자**: 
  - 국영규
  - 강소현
  - 김세희
  - 모인지
  - 윤종윤
  - 임성현
  - 최대현  
  - 이도원
- **불참자**:
  - 이유진


## 회의 안건
1. 서비스 구성도·시스템 구성도 및 화면/유저 플로우
2. 프론트엔드·백엔드·AI 서버·세션 구조 및 API 개념
3. RAG·벡터 DB·평가 모델·RagFlow 활용
4. AI 챗봇·어시스턴트의 개인화 전략 및 데이터 연계
5. 퀴즈·오답 노트·FAQ·신고 기능 및 채팅창 구조
6. 로그 분석·AIOps·평가 지표(KPI)·모니터링
7. 교육 영상·시각화 자료·오픈소스 활용

## 회의 내용

### 안건 1: 서비스 구성도·시스템 구성도 및 화면/유저 플로우
- **논의 내용**:
  - 서비스 구성도와 시스템 구성도의 개념을 구분해야 하며, 클라우드 구성도 자체를 잘 잡으면 서비스 구성 측면에서도 비용을 줄이는 방향이 될 수 있음
  - 화면 기획은 피그마 기반으로 진행 중이며, 단순 ‘UI 설계’에 그치지 않고 ‘유저 플로우(화면 전환·행동 흐름)’까지 포함해서 보는 것이 중요
  - 화면 디자인은 실제 발표 시에는 직접 보여주는 방식이 바람직하며, 단순 링크 공유만으로는 충분하지 않을 수 있음
  - 서비스 구성도(비즈니스/기능 관점)와 시스템 구성도(인프라/기술 관점)를 문서에서 명확히 분리해 제시할 필요가 있음

### 안건 2: 프론트엔드·백엔드·AI 서버·세션 구조 및 API 개념
- **논의 내용**: 
  - 유저가 채팅창에 입력하면,
    - 프론트에서 메시지를 API로 백엔드로 전달
    - DB 저장 후 섹션/인텐트 정보를 통해 DB에서 데이터를 조회
    - 이를 기반으로 ’AI 서버(LLM)’에 전달해 응답을 생성하는 흐름을 설명
  - ‘브라우저 세션’ 개념 관련:
      챗 입력의 첫 시도가 세션 시작으로 간주되며, 이전 데이터를 가져오는 구조는 있으나 방(채팅방) 단위 세션과는 다르게 동작할 수 있음
  - API 설계 관련:
      RAG 관련 API를 포함해 규정집 등 정형 데이터에 대한 API 스펙을 정의해야 하며, 각 API는 어떤 메서드(POST/GET 등)를 사용하고, 어떤 파라미터(조건)를 받아야 하는지 명확하게 설계할 필요가 있음
  - 인텐트/도메인 → 어떤 API(1번~40번 등)로 이어지는지 매핑 구조 설계가 중요

### 안건 3: RAG·벡터 DB·평가 모델·RagFlow 활용
- **논의 내용**:
  - 여러 임베딩·LLM 후보 모델(Qwen2 등)을 선정해 정확도를 측정해 보았고, 소수점 둘째 자리 기준으로 비교했을 때 한 모델이 상대적으로 우수하여 큰 방향성은 잡힌 상태
  - 임베딩 모델과 LLM 모델이 동일한지에 대한 질문이 있었고, 임베딩 모델에 대한 내부 이해가 아직 부족해 추가 확인이 필요
  - RagFlow 관련:
      사용법(인터페이스·설정)을 익히는 데 시간이 많이 걸려 그 시간에 다른 모델/구조를 직접 구현하는 것이 더 빠를 수도 있음
      RagFlow가 제공하는 시각화·인터페이스가 그대로는 아니더라도 동일한 청크 구조로 밀어 넣을 수 있다면 유사한 기능을 재현 가능 여부
      → 한글/HWP, 슬라이드형 PDF 등 RagFlow가 처리하기 어려운 문서는 우리 파이프라인에서 전처리·데이터셋화하고, RagFlow는 두 데이터셋을 합쳐 벡터 DB와 임베딩만 담당하도록 부분적으로만 활용함으로써 유연성과 품질을 동시에 확보하고자 함
  - RAG 테스트/평가:
      지금까지는 ‘느낌’ 위주의 테스트(여러 설정을 바꿔보며 응답 품질 비교)에 가까웠고, 정식 평가 환경·지표를 갖춰 성능을 비교한 것은 아니었음
      → RAG 평가 모델 중 하나로 ‘RAGAS’를 언급하며, 이를 활용하면 시간은 걸리더라도 정량적 평가·지표 도출이 가능하니, 발표 시 ‘청킹/임베딩 전략 비교·평가’를 넣으면 좋음
      → RagFlow 자체는 청크 개수, 원문–청크 매핑 정도만 보여주기 때문에, ‘품질 지표’ 관점에서는 한계가 있음
  - ‘우리만의 벡터 DB’를 사용할 수 있다면, 동일한 환경을 다른 조도 사용할 수 있다는 점을 감안하여 품질 향상 근거·대시보드 노출 방식까지 포함해 특장점으로 풀어내야 함
  - RAG 도입 여부 자체보다 어떤 청킹·임베딩 전략을 선택했고, 어떤 지표로 품질을 평가했는지, 그 결과를 어떻게 대시보드·FAQ·퀴즈 등 서비스 기능으로 녹였는지가 중요

### 안건 4: AI 챗봇·어시스턴트의 개인화 전략 및 데이터 연계
- **논의 내용**:
  - 개인화 개념:
      교육·퀴즈 영역에서의 개인화를 핵심으로 설정
      예: “나 어떤 교육까지 들었어?”, “지금 들어야 할 교육과 퀴즈 정리해줘”, “내가 푼 퀴즈 중 틀린 것만 보고 싶어” 등
      이를 위해 개인별 교육 이력·퀴즈 결과가 DB에 저장되어 있어야 하고, 챗봇이 이 데이터를 불러와 사용자 맞춤 교육/퀴즈 리스트를 보여주는 흐름 구상
  - 개인화를 제대로 구현하려면, 사내 데이터(교육 이수, 부서, 직급 등)를 어느 부서에서 어떤 형태로 제공받아 또 다른 부서/시스템이 재사용할 수 있는지까지 고민해야 함
  - 챗봇·어시스턴트에서 개인화는 매우 중요한 차별 포인트
    다만, 금전적 요소(복지포인트 등)와 강하게 결합하면 책임과 리스크가 커질 수 있어 신중하게 다뤄야 함
  - “질문에 필요한 조건이 모두 나오지 않을 수 있다”는 점을 전제로, API·데이터 설계 측면에서 “개인화에 근접할 수 있는 fallback 전략(‘개인화 기능’을 못 쓸 때, 그 다음으로 안전하고 합리적인 ‘대체 행동’을 미리 정해두기)”도 함께 논의
  - 도메인·인텐트 설계 시, 단순 QA(Question Answering 질의응답)용 개인화가 아니라 “내 교육/퀴즈/진행 상황을 관리해주는 어시스턴트(어시스턴트 레벨 개인화)” 느낌을 강화할 필요

### 안건 5: 퀴즈·오답 노트·FAQ·신고 기능 및 채팅창 구조
- **논의 내용**:
  - 퀴즈/오답 노트:
      퀴즈 기능은 프로젝트의 강한 특장점
      교육의 질을 높이기 위해 부서별 경쟁·점수제·복지포인트 지급 등 시나리오 논의
  - 오답 노트:
      틀린 문항과 사용자가 선택한 정답·해설 중, 해설 위주로 제공하고 단순히 ‘찍었던 답’만 보여주지는 않는 방향으로 설정
  - FAQ:
      FAQ는 “채팅이 없는 상황에서도 자주 묻는 질문으로 문제를 예방하는 기능”이 될 수 있으나, 모든 응답 수집을 강제하는 방식은 뉴스·개인정보 측면에서 부정적일 수 있음
  - 채팅창 카드(규정 안내·FAQ·퀴즈·교육 등):
      현재 채팅창에 네 가지 카드가 있고, 각각에서 채팅이 가능하도록 기획되어 있음
      다만, ‘규정 안내’의 경우 UX 관점에서 얼마나 메리트 있는지에 대해 재검토 필요
  - 신고 기능:
      익명성이 필요하고, 악용 가능성·프로세스 복잡성·관리자 페이지 증가 등을 고려하면 프로젝트 범위 내에서 다루기에는 무거운 주제
      타깃 기업을 상정했을 때, 실제로는 별도 전문팀·프로세스가 필요해 이번 프로젝트의 핵심 범위에서 제외하는 편이 나을 수 있음
  - 신고 기능은 “있으면 좋음” 수준이 아니라 리스크와 책임이 큰 기능이므로 이번 프로젝트의 핵심 주제·공수 대비 효과를 다시 검토해야 함

### 안건 6: 로그 분석·AIOps·평가 지표(KPI)·모니터링
- **논의 내용**:
  - FAQ/챗봇 로그 수집:
      질문이 없을 때도 FAQ/로그를 많이 보여주기 위해 전체 채팅 로그 수집을 고려했으나, 모든 응답 수집 강제 방식은 부정적 측면이 있을 수 있음
  - 로그 분석의 목적:
      응답이 100% 정확하지 않더라도, “왜 이런 답이 나왔는지”에 대한 ‘최소한의 이유·근거(팩트 소스)’가 함께 나오면 좋겠음
  - 도메인별 평가 관리:
      교육/규정/FAQ 등 도메인별로 평가·지표를 관리하는 계획이 언급됨
  - AIOps:
      AIOps 파이프라인·과정에서 사용할 도구·프레임워크(예: 로그 수집, 모니터링, 알람 등)는 아직 확정되지 않음
      AI 평가 지표(KPI)를 잡고 성공/실패 기준, 목표 퍼센트 등을 논의해야 함
  - 모니터링:
      챗봇 대화의 ‘시작–끝’을 어떻게 정의할지에 따라 모니터링 단위가 달라지며, 분석 결과를 바탕으로 다음 액션(교육 개편, FAQ 보강 등)을 설계할 수 있어야 함
  - “AI를 도입했다”보다, 어떤 로그·지표를 보고 어떤 품질 향상 액션을 취했는지까지 설명할 수 있어야 프로젝트의 설득력이 커짐

### 안건 7: 교육 영상·시각화 자료·오픈소스 활용
- **논의 내용**:
  - 교육 콘텐츠 시각화:
      ‘교육 영상 생성’보다는 교육 콘텐츠 시각화 자료에 더 가까워 보임
      DTS 엔진을 사용해 스크립트 → 음성을 생성하고, 아바타·슬라이드를 렌더링하는 구조를 고려 중
      아바타는 향후 발전 계획으로, 현재는 슬라이드(PPT 문단 단위 분할) 기반 영상 생성 플로우에 집중
  - 슬라이드·영상 생성:
      하나의 슬라이드를 통째로 쓰는 것이 아니라, 문단 단위로 나눠 여러 개의 짧은 영상을 생성하고 이를 이어 붙이는 방식으로 실험 중
  - 오픈소스 활용:
      오픈소스를 써서 “그들보다 더 잘 만들 수 있는가?”
      단순히 가져다 쓴 것이 아니라, 그 위에서 어떤 개선·기획·품질 향상을 이뤘는지가 중요함
  - AI 영상 생성 기능은 팀의 메인 기능 중 하나임
  - 발표 시에는 “어떤 오픈소스를 어떻게 확장/개선했는가”를 구체적으로 설명할 수 있도록 준비 필요

- **결정 사항**: 
  - 서비스·시스템 구성도 정리: 서비스 구성도(비즈니스/기능)와 시스템 구성도(인프라)를 구분해 작성 (기획 / Infra) (2025-12-02~2025-12-06)
  - API 의도 매핑 정의: 도메인·인텐트별로 어떤 질문이 어떤 API(1~40번 등)에 매핑되는지 구조 정의하고, JSON 예시와 함께 문서화 (BE / AI) (2025-12-02~2025-12-09)
  - 개인화 설계 구체화: “내 교육/퀴즈 현황” 조회 및 추천을 중심으로 개인화 시나리오 정리, 필요한 DB 스키마·조회 API 요구사항 정의 (기획 / BE) (2025-12-03~2025-12-10)
  - 퀴즈·오답 노트 설계: 퀴즈·오답 노트의 화면 플로우, 점수 집계, 부서별 경쟁/복지포인트 시나리오를 요구사항 명세서로 정리, 보안/악용 방지 방안을 함께 기술 (기획 / FE / AI) (2025-12-03~2025-12-11)
  - RAG 평가·지표 설계: RAG 테스트용 문서·질문 세트 선정, RAGAS 등 평가 도구 활용 여부를 포함해 정량 평가 지표(정확도, 커버리지 등) 정의 (AI) (2025-12-02~2025-12-12)
  - RagFlow 활용 전략: RagFlow 부분 활용 전략 및 자체 RAG 파이프라인 설계 방안 구상 (BE / AI) (2025-12-02~2025-12-07)
  - 로그·AIOps 전략: 도메인별 로그 수집 항목, 모니터링 지표(KPI), AIOps 파이프라인에서 사용할 도구/프레임워크 후보 정리 (Infra / AI) (2025-12-04~2025-12-13)
  - FAQ·질문 제한 정책: 도메인별 질문 수 제한(최대 4개) 및 FAQ에 LLM 호출을 최소화하는 정책 정리, FAQ 화면/플로우 시안에 반영 (기획 / FE) (2025-12-05~2025-12-12)
  - 신고 기능 범위 결정: 신고 기능을 이번 프로젝트에서 포함할지 여부 및 포함할 경우 최소 범위·책임 범위·관리자 기능을 어떻게 제한할지 팀 내부 합의를 거쳐 최종 결정 (2025-12-05~2025-12-09)
  - 교육 영상·시각화 PoC: 슬라이드 문단 단위 분할 → 영상 생성 → 병합 플로우를 한 번 끝까지 PoC로 구현, 오픈소스 대비 개선 포인트 정리 (AI / FE) (2025-12-06~2025-12-16)


## 다음 회의
- **일시**: 2025-12-02

## 기타 사항
- 모든 회의록은 GitHub의 docs/meeting-notes/ 디렉토리에 저장
- 회의록은 회의 종료 후 24시간 내에 공유

---
**작성자**: 이유진  

**작성일**: 2025-11-29
